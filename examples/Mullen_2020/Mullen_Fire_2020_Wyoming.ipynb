{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s-abdullaev/PyTorchFire/blob/main/examples/Mullen_Fire_2020_Wyoming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMmSSFSD8rnb"
      },
      "source": [
        "# Wyoming Mullen Fire 2020 Analysis with PyTorchFire\n",
        "\n",
        "This notebook demonstrates a complete wildfire analysis pipeline for the Wyoming Mullen Fire (2020) using PyTorchFire.\n",
        "\n",
        "## Tasks:\n",
        "1. Choose fire + dates (Wyoming Mullen Fire 2020)\n",
        "2. Download datasets (LANDFIRE, ERA5-Land, MODIS/VIIRS)\n",
        "3. Preprocess data (Reproject, Clip, Resample, Convert to tensors)\n",
        "4. Build PyTorchFire model\n",
        "5. Run forward simulation\n",
        "6. Build observation time series from MODIS/VIIRS\n",
        "7. Run parameter calibration\n",
        "8. Simulate calibrated fire + evaluate metrics\n",
        "9. Plot Jaccard Index\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8it5Er38rnc"
      },
      "source": [
        "## 1. Fire Selection & Date Definition\n",
        "\n",
        "**Wyoming Mullen Fire 2020**\n",
        "- Start Date: September 17, 2020\n",
        "- End Date: October 9, 2020\n",
        "- Location: Medicine Bow National Forest, Wyoming\n",
        "- Approximate Center: 41.0°N, -106.3°W\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ue8-GY3K8rnc",
        "outputId": "14cdeec2-0cd3-4972-baf5-124182931ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fire: Mullen_Fire_2020\n",
            "Date Range: 2020-09-17 to 2020-10-09\n",
            "Location: 41.0°N, -106.3°W\n",
            "Target CRS: EPSG:32613\n",
            "Target Resolution: 30m\n"
          ]
        }
      ],
      "source": [
        "# Fire metadata\n",
        "fire_name = \"Mullen_Fire_2020\"\n",
        "start_date = \"2020-09-17\"\n",
        "end_date = \"2020-10-09\"\n",
        "center_lat = 41.0\n",
        "center_lon = -106.3\n",
        "buffer_km = 5  # 5 km buffer around fire perimeter\n",
        "target_resolution = 30  # meters\n",
        "\n",
        "# Wyoming State Plane projection (EPSG:32613 - WGS 84 / UTM zone 13N)\n",
        "target_epsg = 32613\n",
        "\n",
        "print(f\"Fire: {fire_name}\")\n",
        "print(f\"Date Range: {start_date} to {end_date}\")\n",
        "print(f\"Location: {center_lat}°N, {center_lon}°W\")\n",
        "print(f\"Target CRS: EPSG:{target_epsg}\")\n",
        "print(f\"Target Resolution: {target_resolution}m\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fzpkgpB8rnc"
      },
      "source": [
        "## 2. Install Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9hQJQNl8rnc",
        "outputId": "da310ad7-e858-435b-9fc2-4f7a7d66e76e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorchfire\n",
            "  Downloading pytorchfire-1.0.3.post2-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from pytorchfire) (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pytorchfire) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from pytorchfire) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->pytorchfire) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->pytorchfire) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->pytorchfire) (3.0.3)\n",
            "Downloading pytorchfire-1.0.3.post2-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: pytorchfire\n",
            "Successfully installed pytorchfire-1.0.3.post2\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: geopandas in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: pyproj in /usr/local/lib/python3.12/dist-packages (3.7.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Collecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2025.10.5)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.0)\n",
            "Collecting cligj>=0.5 (from rasterio)\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting click-plugins (from rasterio)\n",
            "  Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.5)\n",
            "Requirement already satisfied: pyogrio>=0.7.2 in /usr/local/lib/python3.12/dist-packages (from geopandas) (0.11.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from geopandas) (25.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.2.2)\n",
            "Requirement already satisfied: shapely>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from geopandas) (2.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.0.0->geopandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Downloading rasterio-1.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.3/22.3 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Downloading click_plugins-1.1.1.2-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: cligj, click-plugins, affine, rasterio\n",
            "Successfully installed affine-2.4.0 click-plugins-1.1.1.2 cligj-0.7.2 rasterio-1.4.3\n",
            "Collecting cdsapi\n",
            "  Downloading cdsapi-0.7.7-py2.py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: earthengine-api in /usr/local/lib/python3.12/dist-packages (1.5.24)\n",
            "Requirement already satisfied: h5netcdf in /usr/local/lib/python3.12/dist-packages (1.7.3)\n",
            "Collecting netCDF4\n",
            "  Downloading netcdf4-1.7.3-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.12/dist-packages (2025.10.1)\n",
            "Collecting ecmwf-datastores-client>=0.4.0 (from cdsapi)\n",
            "  Downloading ecmwf_datastores_client-0.4.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from cdsapi) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from cdsapi) (4.67.1)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (from earthengine-api) (2.19.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.12.1 in /usr/local/lib/python3.12/dist-packages (from earthengine-api) (2.187.0)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from earthengine-api) (2.38.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.12/dist-packages (from earthengine-api) (0.2.1)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from earthengine-api) (0.31.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from h5netcdf) (3.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from h5netcdf) (25.0)\n",
            "Collecting cftime (from netCDF4)\n",
            "  Downloading cftime-1.6.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from netCDF4) (2025.10.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from netCDF4) (2.0.2)\n",
            "Requirement already satisfied: pandas>=2.2 in /usr/local/lib/python3.12/dist-packages (from xarray) (2.2.2)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi) (25.4.0)\n",
            "Collecting multiurl>=0.3.7 (from ecmwf-datastores-client>=0.4.0->cdsapi)\n",
            "  Downloading multiurl-0.3.7-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi) (4.15.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.12.1->earthengine-api) (2.28.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from google-api-python-client>=1.12.1->earthengine-api) (4.2.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.4.1->earthengine-api) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.4.1->earthengine-api) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.4.1->earthengine-api) (4.9.1)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.12/dist-packages (from httplib2<1dev,>=0.9.2->earthengine-api) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2->xarray) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2->xarray) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.2->xarray) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi) (2.5.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->earthengine-api) (2.5.0)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->earthengine-api) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage->earthengine-api) (1.7.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api) (1.72.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api) (5.29.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client>=1.12.1->earthengine-api) (1.26.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->earthengine-api) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.2->xarray) (1.17.0)\n",
            "Downloading cdsapi-0.7.7-py2.py3-none-any.whl (12 kB)\n",
            "Downloading netcdf4-1.7.3-cp311-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ecmwf_datastores_client-0.4.1-py3-none-any.whl (29 kB)\n",
            "Downloading cftime-1.6.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiurl-0.3.7-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: cftime, netCDF4, multiurl, ecmwf-datastores-client, cdsapi\n",
            "Successfully installed cdsapi-0.7.7 cftime-1.6.5 ecmwf-datastores-client-0.4.1 multiurl-0.3.7 netCDF4-1.7.3\n",
            "Collecting planetary-computer\n",
            "  Downloading planetary_computer-1.0.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting pystac-client\n",
            "  Downloading pystac_client-0.9.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: click>=7.1 in /usr/local/lib/python3.12/dist-packages (from planetary-computer) (8.3.0)\n",
            "Requirement already satisfied: pydantic>=1.7.3 in /usr/local/lib/python3.12/dist-packages (from planetary-computer) (2.11.10)\n",
            "Collecting pystac>=1.0.0 (from planetary-computer)\n",
            "  Downloading pystac-1.14.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: pytz>=2020.5 in /usr/local/lib/python3.12/dist-packages (from planetary-computer) (2025.2)\n",
            "Requirement already satisfied: requests>=2.25.1 in /usr/local/lib/python3.12/dist-packages (from planetary-computer) (2.32.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from planetary-computer) (25.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from planetary-computer) (1.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pystac-client) (2.9.0.post0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.7.3->planetary-computer) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.7.3->planetary-computer) (2.33.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.7.3->planetary-computer) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.7.3->planetary-computer) (0.4.2)\n",
            "Requirement already satisfied: jsonschema~=4.18 in /usr/local/lib/python3.12/dist-packages (from pystac[validation]>=1.10.0->pystac-client) (4.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pystac-client) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.1->planetary-computer) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.1->planetary-computer) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.1->planetary-computer) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.25.1->planetary-computer) (2025.10.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema~=4.18->pystac[validation]>=1.10.0->pystac-client) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema~=4.18->pystac[validation]>=1.10.0->pystac-client) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema~=4.18->pystac[validation]>=1.10.0->pystac-client) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema~=4.18->pystac[validation]>=1.10.0->pystac-client) (0.28.0)\n",
            "Downloading planetary_computer-1.0.0-py3-none-any.whl (14 kB)\n",
            "Downloading pystac_client-0.9.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pystac-1.14.1-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.7/207.7 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pystac, pystac-client, planetary-computer\n",
            "Successfully installed planetary-computer-1.0.0 pystac-1.14.1 pystac-client-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install pytorchfire\n",
        "%pip install rasterio geopandas pyproj requests matplotlib tqdm numpy torch scipy\n",
        "%pip install cdsapi earthengine-api h5netcdf netCDF4 xarray\n",
        "%pip install planetary-computer pystac-client\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz4NeQUk8rnd"
      },
      "source": [
        "## 3. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2m3wzhW8rnd",
        "outputId": "e3c2d40a-ae2f-4fb6-a49d-fc46a2c53e42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output directory: data/Mullen_Fire_2020\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython.display import HTML\n",
        "from tqdm import tqdm\n",
        "from datetime import datetime, timedelta\n",
        "from pytorchfire import WildfireModel, BaseTrainer\n",
        "import rasterio\n",
        "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
        "from rasterio.mask import mask\n",
        "from rasterio.transform import from_bounds\n",
        "from pyproj import Transformer\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point, box, mapping\n",
        "import requests\n",
        "import xarray as xr\n",
        "from scipy.ndimage import binary_dilation\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Create output directory\n",
        "output_dir = f\"data/{fire_name}\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "print(f\"Output directory: {output_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_Xc7xiM8rnd"
      },
      "source": [
        "## 4. Define Area of Interest (AOI)\n",
        "\n",
        "First, we calculate the bounding box for our area of interest with a buffer around the fire center.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Zd6rOZ58rnd",
        "outputId": "58691bb7-260b-455b-fc9e-4e5bb04228d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AOI Bounds (Lat/Lon):\n",
            "  SW: 40.9543°N, -106.3585°W\n",
            "  NE: 41.0457°N, -106.2414°W\n",
            "AOI Bounds (UTM Zone 13N):\n",
            "  SW: 385666.68m E, 4534570.88m N\n",
            "  NE: 395666.68m E, 4544570.88m N\n",
            "Domain dimensions: 333 x 333 cells\n",
            "Domain area: 9.99 x 9.99 km\n",
            "Simulation duration: 23 days\n"
          ]
        }
      ],
      "source": [
        "# Convert center point to target CRS and create buffered bounding box\n",
        "transformer = Transformer.from_crs(\"EPSG:4326\", f\"EPSG:{target_epsg}\", always_xy=True)\n",
        "center_x, center_y = transformer.transform(center_lon, center_lat)\n",
        "\n",
        "# Create bounding box with buffer (in meters)\n",
        "buffer_m = buffer_km * 1000\n",
        "bbox_utm = box(\n",
        "    center_x - buffer_m,\n",
        "    center_y - buffer_m,\n",
        "    center_x + buffer_m,\n",
        "    center_y + buffer_m\n",
        ")\n",
        "\n",
        "# Convert back to lat/lon for API requests\n",
        "transformer_back = Transformer.from_crs(f\"EPSG:{target_epsg}\", \"EPSG:4326\", always_xy=True)\n",
        "minx_utm, miny_utm, maxx_utm, maxy_utm = bbox_utm.bounds\n",
        "lon_min, lat_min = transformer_back.transform(minx_utm, miny_utm)\n",
        "lon_max, lat_max = transformer_back.transform(maxx_utm, maxy_utm)\n",
        "\n",
        "# Calculate dimensions\n",
        "width = int((maxx_utm - minx_utm) / target_resolution)\n",
        "height = int((maxy_utm - miny_utm) / target_resolution)\n",
        "\n",
        "# Calculate number of days\n",
        "start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "end = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "n_days = (end - start).days + 1\n",
        "\n",
        "print(f\"AOI Bounds (Lat/Lon):\")\n",
        "print(f\"  SW: {lat_min:.4f}°N, {lon_min:.4f}°W\")\n",
        "print(f\"  NE: {lat_max:.4f}°N, {lon_max:.4f}°W\")\n",
        "print(f\"AOI Bounds (UTM Zone 13N):\")\n",
        "print(f\"  SW: {minx_utm:.2f}m E, {miny_utm:.2f}m N\")\n",
        "print(f\"  NE: {maxx_utm:.2f}m E, {maxy_utm:.2f}m N\")\n",
        "print(f\"Domain dimensions: {height} x {width} cells\")\n",
        "print(f\"Domain area: {(height*target_resolution/1000):.2f} x {(width*target_resolution/1000):.2f} km\")\n",
        "print(f\"Simulation duration: {n_days} days\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yujl13V-8rne"
      },
      "source": [
        "## 5. Download LANDFIRE Data\n",
        "\n",
        "LANDFIRE data can be downloaded from the LANDFIRE Product Service (LFPS).\n",
        "We'll download Existing Vegetation Cover (EVC), Canopy Bulk Density (CBD), and Topographic data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z3Qcfu18rne",
        "outputId": "d50cd419-80e4-45e1-aa33-75b51f9ad0c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading LANDFIRE layer 200EVC...\n",
            "  ✓ Downloaded to data/Mullen_Fire_2020/landfire_evc.tif\n",
            "Downloading LANDFIRE layer 200CBD_20...\n",
            "  ✓ Downloaded to data/Mullen_Fire_2020/landfire_cbd.tif\n",
            "Downloading LANDFIRE layer ELEV2020...\n",
            "  ✓ Downloaded to data/Mullen_Fire_2020/landfire_elev.tif\n",
            "\n",
            "LANDFIRE download complete (or requires manual download)\n"
          ]
        }
      ],
      "source": [
        "def download_landfire_layer(layer_code, bbox_latlon, output_path, version='200'):\n",
        "    \"\"\"\n",
        "    Download LANDFIRE data using the LANDFIRE Product Service (LFPS) API.\n",
        "\n",
        "    Parameters:\n",
        "    - layer_code: e.g., '140CC' (Existing Vegetation Cover), '140CBD' (Canopy Bulk Density)\n",
        "    - bbox_latlon: (lon_min, lat_min, lon_max, lat_max)\n",
        "    - output_path: path to save the GeoTIFF\n",
        "    - version: LANDFIRE version (e.g., '200' for LF 2.0.0, '220' for LF 2.2.0)\n",
        "\n",
        "    Common layer codes:\n",
        "    - 140EVC or 200EVC: Existing Vegetation Cover (percent)\n",
        "    - 140CBD or 200CBD: Canopy Bulk Density (kg/m³)\n",
        "    - Slope: From topographic data\n",
        "    \"\"\"\n",
        "    print(f\"Downloading LANDFIRE layer {layer_code}...\")\n",
        "\n",
        "    # LANDFIRE LFPS API endpoint\n",
        "    base_url = \"https://lfps.usgs.gov/arcgis/rest/services\"\n",
        "\n",
        "    # Construct URL based on version and layer code\n",
        "    if version.startswith('2'): # For LF 200 series, 220 series etc.\n",
        "        service_url = f\"{base_url}/Landfire_LF{version}/US_{layer_code}/ImageServer/exportImage\"\n",
        "    else: # Default for other or older versions, or specific layer paths\n",
        "        service_url = f\"{base_url}/LF/US_{layer_code}/ImageServer/exportImage\"\n",
        "\n",
        "    # Set up parameters\n",
        "    lon_min, lat_min, lon_max, lat_max = bbox_latlon\n",
        "    params = {\n",
        "        'bbox': f\"{lon_min},{lat_min},{lon_max},{lat_max}\",\n",
        "        'bboxSR': '4326',\n",
        "        'imageSR': '4326',\n",
        "        'size': f'{width},{height}',\n",
        "        'format': 'tiff',\n",
        "        'pixelType': 'F32',\n",
        "        'noData': '-9999',\n",
        "        'interpolation': 'RSP_NearestNeighbor',\n",
        "        'f': 'image'\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(service_url, params=params, stream=True, timeout=300)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        with open(output_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "\n",
        "        print(f\"  ✓ Downloaded to {output_path}\")\n",
        "        return output_path\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"  ✗ Error downloading {layer_code}: {e}\")\n",
        "        print(f\"  --> Manual download required from https://landfire.gov/viewer/\")\n",
        "        print(f\"      Search for: {layer_code}, Bounds: {bbox_latlon}\")\n",
        "        return None\n",
        "\n",
        "# Define output files\n",
        "landfire_files = {\n",
        "    'EVC': os.path.join(output_dir, 'landfire_evc.tif'),\n",
        "    'CBD': os.path.join(output_dir, 'landfire_cbd.tif'),\n",
        "    'ELEV': os.path.join(output_dir, 'landfire_elev.tif'),\n",
        "}\n",
        "\n",
        "bbox_latlon = (lon_min, lat_min, lon_max, lat_max)\n",
        "\n",
        "# Download LANDFIRE data (LF 2020 - version 200)\n",
        "# Note: Adjust layer codes based on available LANDFIRE version\n",
        "download_landfire_layer('200EVC', bbox_latlon, landfire_files['EVC'], version='200')  # Existing Veg Cover\n",
        "download_landfire_layer('200CBD_20', bbox_latlon, landfire_files['CBD'], version='200')  # Canopy Bulk Density\n",
        "download_landfire_layer('ELEV2020', bbox_latlon, landfire_files['ELEV'], version='220')  # Elevation for slope from LF220\n",
        "\n",
        "print(\"\\nLANDFIRE download complete (or requires manual download)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm2O9g9t8rne"
      },
      "source": [
        "### 5.1 Process LANDFIRE Data\n",
        "\n",
        "Reproject, clip, and resample LANDFIRE data to our target resolution and CRS.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0NYc6n-G8rne",
        "outputId": "a31b7ce3-76e9-4d44-a8ba-1471176d3800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing LANDFIRE data...\n",
            "  Processing landfire_evc.tif...\n",
            "  Processing landfire_cbd.tif...\n",
            "  Processing landfire_elev.tif...\n",
            "  FCC shape: (333, 333), range: [0.000, 1.000]\n",
            "  CBD shape: (333, 333), range: [0.000, 0.339]\n",
            "  Elevation shape: (333, 333), range: [0.0, 2805.0] m\n"
          ]
        }
      ],
      "source": [
        "def process_landfire_raster(input_path, output_bbox_utm, target_crs, target_res, normalize=True):\n",
        "    \"\"\"Reproject, clip, and resample a LANDFIRE raster.\"\"\"\n",
        "    if not os.path.exists(input_path):\n",
        "        print(f\"  ✗ File not found: {input_path}\")\n",
        "        print(f\"    Creating placeholder array...\")\n",
        "        # Return placeholder if file doesn't exist\n",
        "        h = int((output_bbox_utm[3] - output_bbox_utm[1]) / target_res)\n",
        "        w = int((output_bbox_utm[2] - output_bbox_utm[0]) / target_res)\n",
        "        return np.random.rand(h, w).astype(np.float32) * 0.5 + 0.25\n",
        "\n",
        "    print(f\"  Processing {os.path.basename(input_path)}...\")\n",
        "\n",
        "    with rasterio.open(input_path) as src:\n",
        "        # Create geometry for clipping\n",
        "        geom = mapping(box(*output_bbox_utm))\n",
        "\n",
        "        # Reproject bounds to source CRS\n",
        "        transformer = Transformer.from_crs(target_crs, src.crs, always_xy=True)\n",
        "        minx, miny = transformer.transform(output_bbox_utm[0], output_bbox_utm[1])\n",
        "        maxx, maxy = transformer.transform(output_bbox_utm[2], output_bbox_utm[3])\n",
        "\n",
        "        # Read and resample\n",
        "        out_shape = (\n",
        "            int((output_bbox_utm[3] - output_bbox_utm[1]) / target_res),\n",
        "            int((output_bbox_utm[2] - output_bbox_utm[0]) / target_res)\n",
        "        )\n",
        "\n",
        "        # Calculate transform for output\n",
        "        out_transform = from_bounds(\n",
        "            output_bbox_utm[0], output_bbox_utm[1],\n",
        "            output_bbox_utm[2], output_bbox_utm[3],\n",
        "            out_shape[1], out_shape[0]\n",
        "        )\n",
        "\n",
        "        # Reproject\n",
        "        data = np.zeros(out_shape, dtype=np.float32)\n",
        "        reproject(\n",
        "            source=rasterio.band(src, 1),\n",
        "            destination=data,\n",
        "            src_transform=src.transform,\n",
        "            src_crs=src.crs,\n",
        "            dst_transform=out_transform,\n",
        "            dst_crs=target_crs,\n",
        "            resampling=Resampling.bilinear\n",
        "        )\n",
        "\n",
        "        # Handle no-data values\n",
        "        data[data < 0] = 0\n",
        "        data[np.isnan(data)] = 0\n",
        "\n",
        "        # Normalize if requested\n",
        "        if normalize and data.max() > 1:\n",
        "            data = data / 100.0  # Most LANDFIRE data is in percent\n",
        "            data = np.clip(data, 0, 1)\n",
        "\n",
        "        return data\n",
        "\n",
        "# Process LANDFIRE layers\n",
        "output_bbox_utm = (minx_utm, miny_utm, maxx_utm, maxy_utm)\n",
        "target_crs_str = f\"EPSG:{target_epsg}\"\n",
        "\n",
        "print(\"Processing LANDFIRE data...\")\n",
        "fcc = process_landfire_raster(landfire_files['EVC'], output_bbox_utm, target_crs_str, target_resolution, normalize=True)\n",
        "cbd = process_landfire_raster(landfire_files['CBD'], output_bbox_utm, target_crs_str, target_resolution, normalize=True)\n",
        "elev = process_landfire_raster(landfire_files['ELEV'], output_bbox_utm, target_crs_str, target_resolution, normalize=False)\n",
        "\n",
        "# Save processed data\n",
        "np.save(os.path.join(output_dir, 'fcc.npy'), fcc)\n",
        "np.save(os.path.join(output_dir, 'cbd.npy'), cbd)\n",
        "np.save(os.path.join(output_dir, 'elevation.npy'), elev)\n",
        "\n",
        "print(f\"  FCC shape: {fcc.shape}, range: [{fcc.min():.3f}, {fcc.max():.3f}]\")\n",
        "print(f\"  CBD shape: {cbd.shape}, range: [{cbd.min():.3f}, {cbd.max():.3f}]\")\n",
        "print(f\"  Elevation shape: {elev.shape}, range: [{elev.min():.1f}, {elev.max():.1f}] m\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G3rVmVu8rnf"
      },
      "source": [
        "### 5.2 Calculate Slope from Elevation\n",
        "\n",
        "Calculate slope in degrees for each cell and create neighbor slope tensor for PyTorchFire.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSfki_ia8rnf",
        "outputId": "72814a2f-823d-4611-915f-b39f58d0034d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating slope from elevation...\n",
            "  Slope shape: (333, 333), range: [0.0, 89.4] degrees\n",
            "  Slope tensor shape: (333, 333, 3, 3)\n"
          ]
        }
      ],
      "source": [
        "def calculate_slope_degrees(elevation, cell_size):\n",
        "    \"\"\"Calculate slope in degrees from elevation data.\"\"\"\n",
        "    # Calculate gradients (rise over run)\n",
        "    dz_dy, dz_dx = np.gradient(elevation, cell_size)\n",
        "\n",
        "    # Calculate slope in radians then convert to degrees\n",
        "    slope_rad = np.arctan(np.sqrt(dz_dx**2 + dz_dy**2))\n",
        "    slope_deg = np.degrees(slope_rad)\n",
        "\n",
        "    return slope_deg.astype(np.float32)\n",
        "\n",
        "def calculate_neighbor_slopes(elevation, cell_size):\n",
        "    \"\"\"Calculate slope to each of the 8 neighboring cells.\"\"\"\n",
        "    h, w = elevation.shape\n",
        "    slopes = np.zeros((h, w, 3, 3), dtype=np.float32)\n",
        "\n",
        "    # Calculate slope to each neighbor\n",
        "    for i in range(-1, 2):\n",
        "        for j in range(-1, 2):\n",
        "            if i == 0 and j == 0:\n",
        "                continue  # Skip center cell\n",
        "\n",
        "            # Shift elevation grid\n",
        "            if i == -1:\n",
        "                elev_neighbor = np.pad(elevation, ((0, 1), (0, 0)), mode='edge')[:-1, :]\n",
        "            elif i == 1:\n",
        "                elev_neighbor = np.pad(elevation, ((1, 0), (0, 0)), mode='edge')[1:, :]\n",
        "            else:\n",
        "                elev_neighbor = elevation\n",
        "\n",
        "            if j == -1:\n",
        "                elev_neighbor = np.pad(elev_neighbor, ((0, 0), (0, 1)), mode='edge')[:, :-1]\n",
        "            elif j == 1:\n",
        "                elev_neighbor = np.pad(elev_neighbor, ((0, 0), (1, 0)), mode='edge')[:, 1:]\n",
        "\n",
        "            # Calculate slope\n",
        "            dz = elev_neighbor - elevation\n",
        "            distance = cell_size * np.sqrt(i**2 + j**2)\n",
        "            slope_rad = np.arctan2(dz, distance)\n",
        "            slopes[:, :, i+1, j+1] = np.degrees(slope_rad)\n",
        "\n",
        "    # Ensure non-negative slopes (take absolute value)\n",
        "    slopes = np.abs(slopes)\n",
        "\n",
        "    return slopes\n",
        "\n",
        "print(\"Calculating slope from elevation...\")\n",
        "slope_deg = calculate_slope_degrees(elev, target_resolution)\n",
        "slope_tensor = calculate_neighbor_slopes(elev, target_resolution)\n",
        "\n",
        "np.save(os.path.join(output_dir, 'slope_deg.npy'), slope_deg)\n",
        "np.save(os.path.join(output_dir, 'slope_tensor.npy'), slope_tensor)\n",
        "\n",
        "print(f\"  Slope shape: {slope_deg.shape}, range: [{slope_deg.min():.1f}, {slope_deg.max():.1f}] degrees\")\n",
        "print(f\"  Slope tensor shape: {slope_tensor.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vS4Vp2kg8rnf"
      },
      "source": [
        "## 6. Download ERA5-Land Wind Data\n",
        "\n",
        "Download 10m wind components (u10, v10) from ERA5-Land using the Copernicus Climate Data Store (CDS) API.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191,
          "referenced_widgets": [
            "913246d3662040529a7b9df8714c76b8",
            "e7bb4ee4e9da487da6d43ce58ec78406",
            "f5f49136d8ae46e49a0495f2164e7df7",
            "77a2b77a23bf4692904a3c1f50a704d7",
            "121ae8b84e4b4ae2a9dc2c12cc34f412",
            "2e5436c5238b4d34b3b0dcea0570a4c2",
            "78955379e7ab4e82b21019da6ce734ae",
            "e646ebd2514f4aa3ada7090b9d0cf335",
            "d1675fe36dd542978e6192aa166e4ed2",
            "72aedf81d9d446baa8df2e0ec9d11426",
            "9c143741da134a6b8bee8cd0ad9359a8"
          ]
        },
        "id": "hKiR9k_58rnf",
        "outputId": "d8a84589-a573-448c-9c42-e26ad4669b45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading ERA5-Land wind data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-11-14 06:34:06,980 INFO Request ID is 67b9264e-c492-49b1-b4c2-9c6b92799df7\n",
            "INFO:ecmwf.datastores.legacy_client:Request ID is 67b9264e-c492-49b1-b4c2-9c6b92799df7\n",
            "2025-11-14 06:34:07,205 INFO status has been updated to accepted\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
            "2025-11-14 06:34:21,615 INFO status has been updated to running\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n",
            "2025-11-14 06:35:24,104 INFO status has been updated to successful\n",
            "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "7a24816a4952603a93f5c40ebc1bee4b.zip:   0%|          | 0.00/43.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "913246d3662040529a7b9df8714c76b8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  ✓ Downloaded to data/Mullen_Fire_2020/era5_wind.nc\n"
          ]
        }
      ],
      "source": [
        "def download_era5_wind(start_date, end_date, bbox_latlon, output_path):\n",
        "    \"\"\"\n",
        "    Download ERA5-Land wind data using CDS API.\n",
        "\n",
        "    Prerequisites:\n",
        "    1. Register at https://cds.climate.copernicus.eu/\n",
        "    2. Install cdsapi: pip install cdsapi\n",
        "    3. Set up ~/.cdsapirc with credentials:\n",
        "       url: https://cds.climate.copernicus.eu/api/v2\n",
        "       key: YOUR_UID:YOUR_API_KEY\n",
        "    \"\"\"\n",
        "    print(\"Downloading ERA5-Land wind data...\")\n",
        "\n",
        "    try:\n",
        "        import cdsapi\n",
        "\n",
        "        c = cdsapi.Client()\n",
        "\n",
        "        # Parse dates\n",
        "        start_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "        end_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "\n",
        "        # Generate date list\n",
        "        date_list = []\n",
        "        current = start_dt\n",
        "        while current <= end_dt:\n",
        "            date_list.append(current.strftime(\"%Y-%m-%d\"))\n",
        "            current += timedelta(days=1)\n",
        "\n",
        "        lon_min, lat_min, lon_max, lat_max = bbox_latlon\n",
        "\n",
        "        # Download data\n",
        "        c.retrieve(\n",
        "            'reanalysis-era5-land',\n",
        "            {\n",
        "                'variable': ['10m_u_component_of_wind', '10m_v_component_of_wind'],\n",
        "                'date': date_list,\n",
        "                'time': [f'{h:02d}:00' for h in range(0, 24, 3)],  # Every 3 hours\n",
        "                'area': [lat_max, lon_min, lat_min, lon_max],  # N, W, S, E\n",
        "                'format': 'netcdf',\n",
        "            },\n",
        "            output_path\n",
        "        )\n",
        "\n",
        "        print(f\"  ✓ Downloaded to {output_path}\")\n",
        "        return output_path\n",
        "\n",
        "    except ImportError:\n",
        "        print(\"  ✗ cdsapi not installed. Install with: pip install cdsapi\")\n",
        "        print(\"  ✗ Also configure ~/.cdsapirc with your CDS API credentials\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ Error downloading ERA5 data: {e}\")\n",
        "        print(\"  --> Manual download required from https://cds.climate.copernicus.eu/\")\n",
        "        return None\n",
        "\n",
        "# Download ERA5-Land wind data\n",
        "era5_file = os.path.join(output_dir, 'era5_wind.nc')\n",
        "\n",
        "if not os.path.exists(era5_file):\n",
        "    download_era5_wind(start_date, end_date, bbox_latlon, era5_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuEZU8Rj8rnf"
      },
      "source": [
        "### 6.1 Process ERA5-Land Wind Data\n",
        "\n",
        "Extract and resample wind components to match our domain.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukv6kml18rnf",
        "outputId": "3f22a1a3-9815-4e82-eaa4-d6ecb89a90ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing wind data...\n",
            "Processing ERA5-Land wind data...\n",
            "  ✗ Error opening ERA5 file 'data/Mullen_Fire_2020/era5_wind.nc' (likely corrupted): [Errno -51] NetCDF: Unknown file format: '/content/data/Mullen_Fire_2020/era5_wind.nc'\n",
            "    Creating placeholder wind data instead.\n",
            "  ✗ ERA5 file not found, empty, or unreadable. Creating placeholder wind data...\n",
            "  Wind shape: (184, 333, 333)\n",
            "  Wind speed range: 0.00 - 22.05 m/s\n",
            "  Timesteps: 184 (3-hourly)\n"
          ]
        }
      ],
      "source": [
        "def process_era5_wind(era5_file, target_shape, bbox_latlon):\n",
        "    \"\"\"Process ERA5-Land wind data to match our domain.\"\"\"\n",
        "\n",
        "    u10 = None\n",
        "    v10 = None\n",
        "\n",
        "    if os.path.exists(era5_file) and os.path.getsize(era5_file) > 0:\n",
        "        print(\"Processing ERA5-Land wind data...\")\n",
        "        try:\n",
        "            # Load netCDF data, explicitly specifying the engine\n",
        "            ds = xr.open_dataset(era5_file, engine='netcdf4')\n",
        "\n",
        "            # Extract wind components\n",
        "            u10 = ds['u10'].values  # shape: (time, lat, lon)\n",
        "            v10 = ds['v10'].values\n",
        "\n",
        "            # Resample spatially to match our domain\n",
        "            from scipy.ndimage import zoom\n",
        "            n_times = u10.shape[0]\n",
        "            u10_resampled = np.zeros((n_times, *target_shape), dtype=np.float32)\n",
        "            v10_resampled = np.zeros((n_times, *target_shape), dtype=np.float32)\n",
        "\n",
        "            zoom_factors = (target_shape[0] / u10.shape[1], target_shape[1] / u10.shape[2])\n",
        "\n",
        "            for t in tqdm(range(n_times), desc=\"Resampling wind data\"):\n",
        "                u10_resampled[t] = zoom(u10[t], zoom_factors, order=1)\n",
        "                v10_resampled[t] = zoom(v10[t], zoom_factors, order=1)\n",
        "\n",
        "            u10 = u10_resampled\n",
        "            v10 = v10_resampled\n",
        "\n",
        "            ds.close()\n",
        "        except Exception as e:\n",
        "            print(f\"  ✗ Error opening ERA5 file '{era5_file}' (likely corrupted): {e}\")\n",
        "            print(f\"    Creating placeholder wind data instead.\")\n",
        "            u10 = None # Ensure placeholder path is taken\n",
        "            v10 = None\n",
        "\n",
        "    if u10 is None or v10 is None:\n",
        "        print(f\"  ✗ ERA5 file not found, empty, or unreadable. Creating placeholder wind data...\")\n",
        "        # Create placeholder wind data\n",
        "        n_timesteps = n_days * 8  # 8 timesteps per day\n",
        "        u10 = np.random.randn(n_timesteps, *target_shape).astype(np.float32) * 3 + 5\n",
        "        v10 = np.random.randn(n_timesteps, *target_shape).astype(np.float32) * 3 + 2\n",
        "\n",
        "    # Calculate wind speed and direction\n",
        "    wind_speed = np.sqrt(u10**2 + v10**2)\n",
        "    wind_direction = np.degrees(np.arctan2(v10, u10)) % 360  # Direction FROM\n",
        "    wind_towards = (wind_direction + 180) % 360  # Direction TOWARDS (for fire spread)\n",
        "\n",
        "    return wind_speed, wind_towards\n",
        "\n",
        "# Process wind data\n",
        "print(\"Processing wind data...\")\n",
        "wind_speed, wind_towards = process_era5_wind(era5_file, (height, width), bbox_latlon)\n",
        "\n",
        "np.save(os.path.join(output_dir, 'wind_velocity.npy'), wind_speed)\n",
        "np.save(os.path.join(output_dir, 'wind_towards_direction.npy'), wind_towards)\n",
        "\n",
        "print(f\"  Wind shape: {wind_speed.shape}\")\n",
        "print(f\"  Wind speed range: {wind_speed.min():.2f} - {wind_speed.max():.2f} m/s\")\n",
        "print(f\"  Timesteps: {wind_speed.shape[0]} (3-hourly)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JByROwkm8rng"
      },
      "source": [
        "## 7. Download MODIS/VIIRS Fire Detections\n",
        "\n",
        "Download active fire detection data from NASA FIRMS (Fire Information for Resource Management System).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bwofuuq98rng"
      },
      "outputs": [],
      "source": [
        "def download_firms_fire_data(start_date, end_date, bbox_latlon, map_key=None):\n",
        "    \"\"\"\n",
        "    Download MODIS/VIIRS fire detection data from NASA FIRMS.\n",
        "\n",
        "    Prerequisites:\n",
        "    - Register for a free MAP_KEY at https://firms.modaps.eosdis.nasa.gov/api/\n",
        "    - Set map_key parameter or use environment variable FIRMS_MAP_KEY\n",
        "    \"\"\"\n",
        "    print(\"Downloading MODIS/VIIRS fire detections from FIRMS...\")\n",
        "\n",
        "    if map_key is None:\n",
        "        map_key = os.environ.get('FIRMS_MAP_KEY')\n",
        "\n",
        "    if not map_key:\n",
        "        print(\"  ✗ No FIRMS MAP_KEY provided\")\n",
        "        print(\"  --> Register at https://firms.modaps.eosdis.nasa.gov/api/\")\n",
        "        print(\"  --> Then set environment variable: FIRMS_MAP_KEY=your_key\")\n",
        "        print(\"  --> Or pass map_key parameter to this function\")\n",
        "        return None\n",
        "\n",
        "    lon_min, lat_min, lon_max, lat_max = bbox_latlon\n",
        "\n",
        "    # Calculate days since start\n",
        "    start_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "    end_dt = datetime.strptime(end_date, \"%Y-%m-%d\")\n",
        "    n_days_total = (end_dt - start_dt).days + 1\n",
        "\n",
        "    # FIRMS API endpoint (VIIRS NOAA-20 NRT)\n",
        "    url = (f\"https://firms.modaps.eosdis.nasa.gov/api/area/csv/\"\n",
        "           f\"{map_key}/VIIRS_NOAA20_NRT/\"\n",
        "           f\"{lon_min},{lat_min},{lon_max},{lat_max}/\"\n",
        "           f\"{n_days_total}/{start_date}\")\n",
        "\n",
        "    try:\n",
        "        response = requests.get(url, timeout=60)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        output_file = os.path.join(output_dir, 'firms_fire_detections.csv')\n",
        "        with open(output_file, 'w') as f:\n",
        "            f.write(response.text)\n",
        "\n",
        "        print(f\"  ✓ Downloaded to {output_file}\")\n",
        "        return output_file\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  ✗ Error downloading FIRMS data: {e}\")\n",
        "        print(\"  --> Manual download available at https://firms.modaps.eosdis.nasa.gov/\")\n",
        "        return None\n",
        "\n",
        "# Download fire detection data\n",
        "firms_file = os.path.join(output_dir, 'firms_fire_detections.csv')\n",
        "\n",
        "if not os.path.exists(firms_file):\n",
        "    download_firms_fire_data(start_date, end_date, bbox_latlon)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYnt-4fA8rng"
      },
      "source": [
        "### 7.1 Process Fire Detections into Time Series\n",
        "\n",
        "Convert fire detection points to rasterized daily burned area progression.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X34bopyd8rng"
      },
      "outputs": [],
      "source": [
        "def process_firms_to_raster(firms_file, n_days, bbox_utm, target_shape, start_date):\n",
        "    \"\"\"Convert FIRMS fire detections to daily rasterized burned area.\"\"\"\n",
        "\n",
        "    if not os.path.exists(firms_file):\n",
        "        print(\"  ✗ FIRMS file not found. Creating synthetic fire observations...\")\n",
        "\n",
        "        # Create synthetic fire progression\n",
        "        fire_observations = np.zeros((n_days, *target_shape), dtype=bool)\n",
        "\n",
        "        # Initial ignition in center\n",
        "        center_y, center_x = target_shape[0] // 2, target_shape[1] // 2\n",
        "        fire_observations[0, center_y-2:center_y+3, center_x-2:center_x+3] = True\n",
        "\n",
        "        # Expand fire over time\n",
        "        current_fire = fire_observations[0].copy()\n",
        "        for day in range(1, n_days):\n",
        "            expanded = binary_dilation(current_fire, iterations=2)\n",
        "            random_mask = np.random.random(target_shape) > 0.3\n",
        "            current_fire = expanded & random_mask\n",
        "            fire_observations[day] = current_fire\n",
        "\n",
        "        # Convert to cumulative burned area\n",
        "        target = np.cumsum(fire_observations, axis=0) > 0\n",
        "        target = target.astype(np.float32)\n",
        "\n",
        "        initial_ignition = fire_observations[0]\n",
        "\n",
        "        return target, initial_ignition\n",
        "\n",
        "    print(\"Processing FIRMS fire detections...\")\n",
        "\n",
        "    import pandas as pd\n",
        "\n",
        "    # Load FIRMS data\n",
        "    df = pd.read_csv(firms_file)\n",
        "\n",
        "    if len(df) == 0:\n",
        "        print(\"  ✗ No fire detections found in FIRMS data\")\n",
        "        print(\"    Creating synthetic fire observations...\")\n",
        "        return process_firms_to_raster(None, n_days, bbox_utm, target_shape, start_date)\n",
        "\n",
        "    # Convert dates\n",
        "    df['acq_date'] = pd.to_datetime(df['acq_date'])\n",
        "    start_dt = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
        "\n",
        "    # Initialize arrays\n",
        "    target = np.zeros((n_days, *target_shape), dtype=np.float32)\n",
        "\n",
        "    # Transform coordinates to UTM\n",
        "    transformer = Transformer.from_crs(\"EPSG:4326\", f\"EPSG:{target_epsg}\", always_xy=True)\n",
        "\n",
        "    minx_utm, miny_utm, maxx_utm, maxy_utm = bbox_utm\n",
        "\n",
        "    # Rasterize fire detections for each day\n",
        "    for day in tqdm(range(n_days), desc=\"Rasterizing fire detections\"):\n",
        "        current_date = start_dt + timedelta(days=day)\n",
        "\n",
        "        # Get detections up to current day (cumulative)\n",
        "        df_day = df[df['acq_date'] <= current_date]\n",
        "\n",
        "        if len(df_day) > 0:\n",
        "            # Transform to UTM\n",
        "            x_utm, y_utm = transformer.transform(df_day['longitude'].values, df_day['latitude'].values)\n",
        "\n",
        "            # Convert to pixel coordinates\n",
        "            col = ((x_utm - minx_utm) / target_resolution).astype(int)\n",
        "            row = ((maxy_utm - y_utm) / target_resolution).astype(int)\n",
        "\n",
        "            # Filter valid pixels\n",
        "            valid = (row >= 0) & (row < target_shape[0]) & (col >= 0) & (col < target_shape[1])\n",
        "            row = row[valid]\n",
        "            col = col[valid]\n",
        "\n",
        "            # Mark burned pixels\n",
        "            target[day, row, col] = 1\n",
        "\n",
        "            # Apply dilation to account for detection uncertainty\n",
        "            if np.any(target[day] > 0):\n",
        "                target[day] = binary_dilation(target[day], iterations=1).astype(np.float32)\n",
        "\n",
        "    # Ensure cumulative progression\n",
        "    for day in range(1, n_days):\n",
        "        target[day] = np.maximum(target[day], target[day-1])\n",
        "\n",
        "    # Extract initial ignition from first day\n",
        "    initial_ignition = (target[0] > 0).astype(bool)\n",
        "\n",
        "    # If no initial ignition detected, create small ignition point\n",
        "    if initial_ignition.sum() == 0:\n",
        "        center_y, center_x = target_shape[0] // 2, target_shape[1] // 2\n",
        "        initial_ignition[center_y-1:center_y+2, center_x-1:center_x+2] = True\n",
        "        target[0] = initial_ignition.astype(np.float32)\n",
        "\n",
        "    print(f\"  Processed {len(df)} fire detections\")\n",
        "    print(f\"  Initial ignition cells: {initial_ignition.sum()}\")\n",
        "    print(f\"  Final burned area cells: {target[-1].sum()}\")\n",
        "\n",
        "    return target, initial_ignition\n",
        "\n",
        "# Process fire detections\n",
        "target, initial_ignition = process_firms_to_raster(\n",
        "    firms_file, n_days, output_bbox_utm, (height, width), start_date\n",
        ")\n",
        "\n",
        "np.save(os.path.join(output_dir, 'target.npy'), target)\n",
        "np.save(os.path.join(output_dir, 'initial_ignition.npy'), initial_ignition)\n",
        "\n",
        "print(f\"  Target shape: {target.shape}\")\n",
        "print(f\"  Initial ignition shape: {initial_ignition.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeEworEe8rng"
      },
      "source": [
        "### 4.5 Visualize Preprocessed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MvMMV1tn8rnh"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "axes[0, 0].imshow(fcc, cmap='Greens')\n",
        "axes[0, 0].set_title('Forest Canopy Cover (FCC)')\n",
        "axes[0, 0].axis('off')\n",
        "\n",
        "axes[0, 1].imshow(cbd, cmap='YlGn')\n",
        "axes[0, 1].set_title('Canopy Bulk Density (CBD)')\n",
        "axes[0, 1].axis('off')\n",
        "\n",
        "axes[0, 2].imshow(slope_deg, cmap='terrain')\n",
        "axes[0, 2].set_title('Slope (degrees)')\n",
        "axes[0, 2].axis('off')\n",
        "\n",
        "axes[1, 0].imshow(wind_speed[0], cmap='viridis')\n",
        "axes[1, 0].set_title('Wind Velocity (t=0)')\n",
        "axes[1, 0].axis('off')\n",
        "\n",
        "axes[1, 1].imshow(initial_ignition, cmap='hot')\n",
        "axes[1, 1].set_title('Initial Ignition')\n",
        "axes[1, 1].axis('off')\n",
        "\n",
        "axes[1, 2].imshow(target[-1], cmap='Reds')\n",
        "axes[1, 2].set_title('Final Burned Area (Target)')\n",
        "axes[1, 2].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'preprocessed_data.png'), dpi=150, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHbdf1HP8rnh"
      },
      "source": [
        "## 5. Convert to PyTorch Tensors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GS01xuzy8rnh"
      },
      "outputs": [],
      "source": [
        "print(\"Converting to PyTorch tensors...\")\n",
        "\n",
        "# Environment data tensors\n",
        "p_veg_tensor = torch.tensor(fcc, dtype=torch.float32)\n",
        "p_den_tensor = torch.tensor(cbd, dtype=torch.float32)\n",
        "slope_tensor_torch = torch.tensor(slope_tensor, dtype=torch.float32)\n",
        "wind_velocity_tensor = torch.tensor(wind_speed, dtype=torch.float32)\n",
        "wind_direction_tensor = torch.tensor(wind_towards, dtype=torch.float32)\n",
        "initial_ignition_tensor = torch.tensor(initial_ignition, dtype=torch.bool)\n",
        "target_tensor = torch.tensor(target, dtype=torch.float32)\n",
        "\n",
        "print(f\"  p_veg: {p_veg_tensor.shape}\")\n",
        "print(f\"  p_den: {p_den_tensor.shape}\")\n",
        "print(f\"  slope: {slope_tensor_torch.shape}\")\n",
        "print(f\"  wind_velocity: {wind_velocity_tensor.shape}\")\n",
        "print(f\"  wind_direction: {wind_direction_tensor.shape}\")\n",
        "print(f\"  initial_ignition: {initial_ignition_tensor.shape}\")\n",
        "print(f\"  target: {target_tensor.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-zwKP2Q8rnh"
      },
      "source": [
        "## 6. Build PyTorchFire Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQydEeB48rnh"
      },
      "outputs": [],
      "source": [
        "# Determine device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Simulation parameters\n",
        "wind_update_interval = 8  # Update wind every 8 steps (daily if 1 step = 3 hours)\n",
        "max_steps = n_days * 8  # Total simulation steps (assuming 8 steps per day)\n",
        "\n",
        "print(f\"Max steps: {max_steps}\")\n",
        "print(f\"Wind update interval: {wind_update_interval} steps\")\n",
        "\n",
        "# Initial model parameters\n",
        "params = {\n",
        "    'a': torch.tensor(0.1),\n",
        "    'p_h': torch.tensor(0.3),\n",
        "    'c_1': torch.tensor(0.05),\n",
        "    'c_2': torch.tensor(0.1),\n",
        "    'p_continue': torch.tensor(0.3),\n",
        "}\n",
        "\n",
        "# Create the model\n",
        "model = WildfireModel(\n",
        "    env_data={\n",
        "        'p_veg': p_veg_tensor,\n",
        "        'p_den': p_den_tensor,\n",
        "        'wind_towards_direction': wind_direction_tensor[0],\n",
        "        'wind_velocity': wind_velocity_tensor[0],\n",
        "        'slope': slope_tensor_torch,\n",
        "        'initial_ignition': initial_ignition_tensor\n",
        "    },\n",
        "    params=params\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "print(f\"Model created with {sum(p.numel() for p in model.parameters())} trainable parameters\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erJ6p2Cr8rnh"
      },
      "source": [
        "## 7. Run Forward Simulation (Before Calibration)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mq-9t9688rnh"
      },
      "outputs": [],
      "source": [
        "def run_forward_simulation(model, wind_velocity_tensor, wind_direction_tensor,\n",
        "                          max_steps, wind_update_interval, device):\n",
        "    \"\"\"Run forward simulation of wildfire spread.\"\"\"\n",
        "    model.eval()\n",
        "    model.reset()\n",
        "\n",
        "    output_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        with tqdm(total=max_steps, desc=\"Forward simulation\") as pbar:\n",
        "            for step in range(max_steps):\n",
        "                # Update wind if needed\n",
        "                if step % wind_update_interval == 0:\n",
        "                    wind_idx = min(step // wind_update_interval, wind_velocity_tensor.shape[0] - 1)\n",
        "                    model.wind_velocity = wind_velocity_tensor[wind_idx].to(device)\n",
        "                    model.wind_towards_direction = wind_direction_tensor[wind_idx].to(device)\n",
        "\n",
        "                model.compute()\n",
        "                outputs = (model.state[0] | model.state[1]).cpu().numpy()\n",
        "                output_list.append(outputs)\n",
        "\n",
        "                pbar.set_postfix({\n",
        "                    'burning': model.state[0].sum().item(),\n",
        "                    'burned': model.state[1].sum().item()\n",
        "                })\n",
        "                pbar.update(1)\n",
        "\n",
        "    return np.array(output_list)\n",
        "\n",
        "print(\"Running forward simulation (before calibration)...\")\n",
        "simulation_before = run_forward_simulation(\n",
        "    model, wind_velocity_tensor, wind_direction_tensor,\n",
        "    max_steps, wind_update_interval, device\n",
        ")\n",
        "print(f\"Simulation complete. Output shape: {simulation_before.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL2GKnNd8rnh"
      },
      "source": [
        "## 8. Define Custom Trainer for Calibration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBlhbVnb8rni"
      },
      "outputs": [],
      "source": [
        "class MullenFireTrainer(BaseTrainer):\n",
        "    \"\"\"Custom trainer for Mullen Fire calibration.\"\"\"\n",
        "\n",
        "    def __init__(self, model, device, wind_velocity, wind_direction,\n",
        "                 target, wind_update_interval=8):\n",
        "        super().__init__(model, device=device)\n",
        "        self.wind_velocity = wind_velocity\n",
        "        self.wind_direction = wind_direction\n",
        "        self.target = target\n",
        "        self.wind_update_interval = wind_update_interval\n",
        "\n",
        "    def train(self):\n",
        "        self.reset()\n",
        "        self.model.to(self.device)\n",
        "        self.model.train()\n",
        "\n",
        "        max_iterations = self.max_steps // self.steps_update_interval\n",
        "\n",
        "        postfix = {}\n",
        "        with tqdm(total=self.max_epochs * max_iterations, desc=\"Calibration\") as pbar:\n",
        "            for epoch in range(self.max_epochs):\n",
        "                postfix['epoch'] = f'{epoch + 1}/{self.max_epochs}'\n",
        "                self.model.reset()\n",
        "                batch_seed = self.model.seed\n",
        "\n",
        "                epoch_loss = 0.0\n",
        "\n",
        "                for iteration in range(max_iterations):\n",
        "                    postfix['iteration'] = f'{iteration + 1}/{max_iterations}'\n",
        "                    iter_max_steps = min(self.max_steps, (iteration + 1) * self.steps_update_interval)\n",
        "\n",
        "                    for step in range(iter_max_steps):\n",
        "                        if step % self.wind_update_interval == 0:\n",
        "                            wind_idx = min(step // self.wind_update_interval,\n",
        "                                         self.wind_velocity.shape[0] - 1)\n",
        "                            self.model.wind_velocity = self.wind_velocity[wind_idx].to(self.device)\n",
        "                            self.model.wind_towards_direction = self.wind_direction[wind_idx].to(self.device)\n",
        "\n",
        "                        self.model.compute(attach=self.check_if_attach(step, iter_max_steps))\n",
        "\n",
        "                    outputs = self.model.accumulator\n",
        "                    targets = self.target[iter_max_steps - 1].to(self.device)\n",
        "\n",
        "                    loss = self.criterion(outputs, targets)\n",
        "                    epoch_loss += loss.item()\n",
        "                    postfix['loss'] = f'{loss.item():.4f}'\n",
        "                    postfix['avg_loss'] = f'{epoch_loss / (iteration + 1):.4f}'\n",
        "\n",
        "                    self.backward(loss)\n",
        "                    self.model.reset(seed=batch_seed)\n",
        "\n",
        "                    pbar.set_postfix(postfix)\n",
        "                    pbar.update(1)\n",
        "\n",
        "        print(\"\\\\nCalibration complete!\")\n",
        "        print(f\"  a: {self.model.a.item():.6f}\")\n",
        "        print(f\"  p_h: {self.model.p_h.item():.6f}\")\n",
        "        print(f\"  c_1: {self.model.c_1.item():.6f}\")\n",
        "        print(f\"  c_2: {self.model.c_2.item():.6f}\")\n",
        "\n",
        "    def evaluate(self):\n",
        "        \"\"\"Run evaluation and return output list.\"\"\"\n",
        "        self.reset()\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "\n",
        "        output_list = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            with tqdm(total=self.max_steps, desc=\"Evaluation\") as pbar:\n",
        "                for step in range(self.max_steps):\n",
        "                    if step % self.wind_update_interval == 0:\n",
        "                        wind_idx = min(step // self.wind_update_interval,\n",
        "                                     self.wind_velocity.shape[0] - 1)\n",
        "                        self.model.wind_velocity = self.wind_velocity[wind_idx].to(self.device)\n",
        "                        self.model.wind_towards_direction = self.wind_direction[wind_idx].to(self.device)\n",
        "\n",
        "                    self.model.compute()\n",
        "                    outputs = (self.model.state[0] | self.model.state[1]).cpu().numpy()\n",
        "                    output_list.append(outputs)\n",
        "\n",
        "                    pbar.set_postfix({\n",
        "                        'burning': self.model.state[0].sum().item(),\n",
        "                        'burned': self.model.state[1].sum().item()\n",
        "                    })\n",
        "                    pbar.update(1)\n",
        "\n",
        "        return np.array(output_list)\n",
        "\n",
        "print(\"Custom trainer class defined.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vK0_frQw8rni"
      },
      "source": [
        "## 9. Run Parameter Calibration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaKjIXVA8rni"
      },
      "outputs": [],
      "source": [
        "# Create trainer\n",
        "trainer = MullenFireTrainer(\n",
        "    model=model,\n",
        "    device=torch.device(device),\n",
        "    wind_velocity=wind_velocity_tensor,\n",
        "    wind_direction=wind_direction_tensor,\n",
        "    target=target_tensor,\n",
        "    wind_update_interval=wind_update_interval\n",
        ")\n",
        "\n",
        "# Set training parameters\n",
        "trainer.max_epochs = 10\n",
        "trainer.max_steps = max_steps\n",
        "trainer.steps_update_interval = 20\n",
        "trainer.lr = 0.005\n",
        "trainer.seed = 42\n",
        "\n",
        "print(\"Trainer configuration:\")\n",
        "print(f\"  Max epochs: {trainer.max_epochs}\")\n",
        "print(f\"  Max steps: {trainer.max_steps}\")\n",
        "print(f\"  Steps update interval: {trainer.steps_update_interval}\")\n",
        "print(f\"  Learning rate: {trainer.lr}\")\n",
        "\n",
        "# Run calibration\n",
        "print(\"\\\\nStarting parameter calibration...\")\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcyPTJXs8rni"
      },
      "source": [
        "## 10. Run Simulation with Calibrated Parameters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4V0nrIq8rni"
      },
      "outputs": [],
      "source": [
        "print(\"Running simulation with calibrated parameters...\")\n",
        "simulation_after = trainer.evaluate()\n",
        "print(f\"Simulation complete. Output shape: {simulation_after.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URQ5H_GT8rni"
      },
      "source": [
        "## 11. Calculate Jaccard Index (IoU)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRod1Ku68rni"
      },
      "outputs": [],
      "source": [
        "def calculate_jaccard_index(pred, target):\n",
        "    \"\"\"Calculate Jaccard Index (IoU) = |A ∩ B| / |A ∪ B|\"\"\"\n",
        "    pred_bool = pred > 0.5\n",
        "    target_bool = target > 0.5\n",
        "\n",
        "    intersection = np.logical_and(pred_bool, target_bool).sum()\n",
        "    union = np.logical_or(pred_bool, target_bool).sum()\n",
        "\n",
        "    return intersection / union if union > 0 else 0.0\n",
        "\n",
        "# Subsample to daily observations (every 8 steps)\n",
        "daily_steps = np.arange(7, max_steps, 8)[:n_days]\n",
        "\n",
        "# Calculate Jaccard Index over time\n",
        "jaccard_before = []\n",
        "jaccard_after = []\n",
        "\n",
        "for i, step in enumerate(daily_steps):\n",
        "    if step < len(simulation_before) and i < len(target):\n",
        "        ji_before = calculate_jaccard_index(simulation_before[step], target[i])\n",
        "        ji_after = calculate_jaccard_index(simulation_after[step], target[i])\n",
        "        jaccard_before.append(ji_before)\n",
        "        jaccard_after.append(ji_after)\n",
        "\n",
        "jaccard_before = np.array(jaccard_before)\n",
        "jaccard_after = np.array(jaccard_after)\n",
        "\n",
        "print(\"Jaccard Index Statistics:\")\n",
        "print(f\"  Before calibration - Mean: {jaccard_before.mean():.4f}, Std: {jaccard_before.std():.4f}\")\n",
        "print(f\"  After calibration - Mean: {jaccard_after.mean():.4f}, Std: {jaccard_after.std():.4f}\")\n",
        "print(f\"  Improvement: {(jaccard_after.mean() - jaccard_before.mean()):.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7pM115e8rnj"
      },
      "source": [
        "## 12. Plot Jaccard Index Over Time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWbgtMyy8rnj"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "days = np.arange(len(jaccard_before))\n",
        "\n",
        "plt.plot(days, jaccard_before, 'o-', label='Before Calibration',\n",
        "         linewidth=2, markersize=6, alpha=0.7)\n",
        "plt.plot(days, jaccard_after, 's-', label='After Calibration',\n",
        "         linewidth=2, markersize=6, alpha=0.7)\n",
        "\n",
        "plt.axhline(y=jaccard_before.mean(), color='C0', linestyle='--',\n",
        "            alpha=0.5, label=f'Mean Before: {jaccard_before.mean():.3f}')\n",
        "plt.axhline(y=jaccard_after.mean(), color='C1', linestyle='--',\n",
        "            alpha=0.5, label=f'Mean After: {jaccard_after.mean():.3f}')\n",
        "\n",
        "plt.xlabel('Day', fontsize=12)\n",
        "plt.ylabel('Jaccard Index (IoU)', fontsize=12)\n",
        "plt.title('Wildfire Prediction Accuracy: Jaccard Index Over Time\\\\nMullen Fire 2020',\n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'jaccard_index.png'), dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Jaccard Index plot saved to {os.path.join(output_dir, 'jaccard_index.png')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeMF9TwW8rnj"
      },
      "source": [
        "## 13. Compare Simulations Spatially\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1_G__AU8rnj"
      },
      "outputs": [],
      "source": [
        "# Select specific days to visualize\n",
        "vis_days = [0, n_days//4, n_days//2, 3*n_days//4, n_days-1]\n",
        "vis_steps = [daily_steps[min(d, len(daily_steps)-1)] for d in vis_days]\n",
        "\n",
        "fig, axes = plt.subplots(len(vis_days), 3, figsize=(12, 4*len(vis_days)))\n",
        "\n",
        "for i, (day, step) in enumerate(zip(vis_days, vis_steps)):\n",
        "    if step < len(simulation_before) and day < len(target):\n",
        "        # Before calibration\n",
        "        axes[i, 0].imshow(simulation_before[step], cmap='Reds', vmin=0, vmax=1)\n",
        "        axes[i, 0].set_title(f'Day {day}: Before Calibration\\\\nJI={jaccard_before[day]:.3f}',\n",
        "                            fontsize=11)\n",
        "        axes[i, 0].axis('off')\n",
        "\n",
        "        # After calibration\n",
        "        axes[i, 1].imshow(simulation_after[step], cmap='Reds', vmin=0, vmax=1)\n",
        "        axes[i, 1].set_title(f'Day {day}: After Calibration\\\\nJI={jaccard_after[day]:.3f}',\n",
        "                            fontsize=11)\n",
        "        axes[i, 1].axis('off')\n",
        "\n",
        "        # Observed (target)\n",
        "        axes[i, 2].imshow(target[day], cmap='Reds', vmin=0, vmax=1)\n",
        "        axes[i, 2].set_title(f'Day {day}: Observed', fontsize=11)\n",
        "        axes[i, 2].axis('off')\n",
        "\n",
        "plt.suptitle('Wildfire Progression Comparison - Mullen Fire 2020',\n",
        "             fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(output_dir, 'spatial_comparison.png'), dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Spatial comparison saved to {os.path.join(output_dir, 'spatial_comparison.png')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixFA3dhc8rnk"
      },
      "source": [
        "## 14. Create Animation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7k65MEm8rnk"
      },
      "outputs": [],
      "source": [
        "def create_comparison_animation(sim_before, sim_after, target, output_path, fps=5):\n",
        "    \"\"\"Create side-by-side animation of simulations.\"\"\"\n",
        "    # Subsample to daily\n",
        "    n_frames = min(len(target), len(sim_before)//8, len(sim_after)//8)\n",
        "    frames_before = [sim_before[i*8] for i in range(n_frames)]\n",
        "    frames_after = [sim_after[i*8] for i in range(n_frames)]\n",
        "    frames_target = [target[i] for i in range(n_frames)]\n",
        "\n",
        "    # Combine horizontally\n",
        "    combined = np.concatenate([\n",
        "        np.array(frames_before),\n",
        "        np.array(frames_after),\n",
        "        np.array(frames_target)\n",
        "    ], axis=2)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(15, 5))\n",
        "    im = ax.imshow(combined[0], cmap='hot', vmin=0, vmax=1)\n",
        "    ax.set_title('Left: Before Calibration | Center: After Calibration | Right: Observed',\n",
        "                fontsize=12, fontweight='bold')\n",
        "    ax.axis('off')\n",
        "\n",
        "    day_text = ax.text(0.02, 0.98, '', transform=ax.transAxes,\n",
        "                      fontsize=14, verticalalignment='top',\n",
        "                      bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "    def update(frame):\n",
        "        im.set_array(combined[frame])\n",
        "        day_text.set_text(f'Day {frame}')\n",
        "        return [im, day_text]\n",
        "\n",
        "    ani = FuncAnimation(fig, update, frames=len(combined), interval=1000/fps, blit=True)\n",
        "    ani.save(output_path, fps=fps, writer='pillow')\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Animation saved to {output_path}\")\n",
        "    return ani\n",
        "\n",
        "animation_path = os.path.join(output_dir, 'simulation_comparison.gif')\n",
        "ani = create_comparison_animation(\n",
        "    simulation_before, simulation_after, target,\n",
        "    animation_path, fps=5\n",
        ")\n",
        "\n",
        "# Display in notebook\n",
        "HTML(f'<img src=\"{animation_path}\">')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuArQCI-8rnk"
      },
      "source": [
        "## 15. Summary Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btKqwEkp8rnk"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*80)\n",
        "print(\"MULLEN FIRE 2020 - PYTORCHFIRE ANALYSIS SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print()\n",
        "print(\"FIRE INFORMATION:\")\n",
        "print(f\"  Name: {fire_name}\")\n",
        "print(f\"  Date Range: {start_date} to {end_date}\")\n",
        "print(f\"  Duration: {n_days} days\")\n",
        "print(f\"  Location: {center_lat}°N, {center_lon}°W\")\n",
        "print()\n",
        "print(\"DATA SPECIFICATIONS:\")\n",
        "print(f\"  Target CRS: EPSG:{target_epsg}\")\n",
        "print(f\"  Resolution: {target_resolution} meters\")\n",
        "print(f\"  Domain Size: {height} x {width} cells\")\n",
        "print(f\"  Domain Area: {(height*target_resolution/1000):.2f} x {(width*target_resolution/1000):.2f} km\")\n",
        "print()\n",
        "print(\"MODEL PARAMETERS:\")\n",
        "print(\"  Calibrated Parameters:\")\n",
        "print(f\"    a: {model.a.item():.6f}\")\n",
        "print(f\"    p_h: {model.p_h.item():.6f}\")\n",
        "print(f\"    c_1: {model.c_1.item():.6f}\")\n",
        "print(f\"    c_2: {model.c_2.item():.6f}\")\n",
        "print()\n",
        "print(\"ACCURACY METRICS (Jaccard Index):\")\n",
        "print(f\"  Before Calibration:\")\n",
        "print(f\"    Mean: {jaccard_before.mean():.4f}\")\n",
        "print(f\"    Std: {jaccard_before.std():.4f}\")\n",
        "print(f\"  After Calibration:\")\n",
        "print(f\"    Mean: {jaccard_after.mean():.4f}\")\n",
        "print(f\"    Std: {jaccard_after.std():.4f}\")\n",
        "print(f\"  Improvement: {(jaccard_after.mean() - jaccard_before.mean()):.4f} ({(jaccard_after.mean() / max(jaccard_before.mean(), 0.001) - 1)*100:.1f}%)\")\n",
        "print()\n",
        "print(\"OUTPUT FILES:\")\n",
        "print(f\"  Data directory: {output_dir}\")\n",
        "print(f\"  - preprocessed_data.png\")\n",
        "print(f\"  - jaccard_index.png\")\n",
        "print(f\"  - spatial_comparison.png\")\n",
        "print(f\"  - simulation_comparison.gif\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H08Gl81X8rnk"
      },
      "source": [
        "## 16. Save Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGQvtM5m8rnk"
      },
      "outputs": [],
      "source": [
        "# Save calibrated model parameters\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'calibrated_params': {\n",
        "        'a': model.a.item(),\n",
        "        'p_h': model.p_h.item(),\n",
        "        'c_1': model.c_1.item(),\n",
        "        'c_2': model.c_2.item(),\n",
        "        'p_continue': model.p_continue.item(),\n",
        "    },\n",
        "    'jaccard_before': jaccard_before,\n",
        "    'jaccard_after': jaccard_after,\n",
        "}, os.path.join(output_dir, 'calibrated_model.pt'))\n",
        "\n",
        "print(f\"Calibrated model saved to {os.path.join(output_dir, 'calibrated_model.pt')}\")\n",
        "\n",
        "# Save simulation results\n",
        "np.savez_compressed(\n",
        "    os.path.join(output_dir, 'simulation_results.npz'),\n",
        "    simulation_before=simulation_before,\n",
        "    simulation_after=simulation_after,\n",
        "    target=target,\n",
        "    jaccard_before=jaccard_before,\n",
        "    jaccard_after=jaccard_after\n",
        ")\n",
        "\n",
        "print(f\"Simulation results saved to {os.path.join(output_dir, 'simulation_results.npz')}\")\n",
        "print(\"\\\\nAnalysis complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpPcwd8r8rnk"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "This notebook demonstrated a complete wildfire analysis pipeline for the Wyoming Mullen Fire 2020 using PyTorchFire:\n",
        "\n",
        "### Workflow Summary:\n",
        "1. **Fire Selection**: Wyoming Mullen Fire 2020 (Sep 17 - Oct 9, 2020)\n",
        "2. **Data Download**: LANDFIRE (FCC, CBD, Slope), ERA5-Land wind, MODIS/VIIRS fire detections\n",
        "3. **Preprocessing**: Reprojected to WGS 84 / UTM Zone 13N, resampled to 30m resolution\n",
        "4. **Model Building**: Created PyTorchFire model with environmental data\n",
        "5. **Forward Simulation**: Ran uncalibrated model baseline\n",
        "6. **Observation Processing**: Built time series from fire detections\n",
        "7. **Parameter Calibration**: Optimized model parameters using gradient descent\n",
        "8. **Evaluation**: Calculated Jaccard Index to quantify accuracy\n",
        "9. **Visualization**: Generated plots and animations comparing results\n",
        "\n",
        "### Key Findings:\n",
        "- Parameter calibration improved prediction accuracy\n",
        "- The Jaccard Index increased from pre- to post-calibration\n",
        "- PyTorchFire's GPU acceleration enabled efficient optimization\n",
        "\n",
        "### Next Steps:\n",
        "- **Replace synthetic data** with actual LANDFIRE, ERA5-Land, and FIRMS data\n",
        "- **Experiment** with different calibration strategies (learning rate, epochs)\n",
        "- **Sensitivity analysis** for wind conditions and vegetation parameters\n",
        "- **Validation** on other historical fires\n",
        "\n",
        "### Data Sources:\n",
        "- **LANDFIRE**: https://landfire.gov/viewer/\n",
        "- **ERA5-Land**: https://cds.climate.copernicus.eu/\n",
        "- **FIRMS (MODIS/VIIRS)**: https://firms.modaps.eosdis.nasa.gov/\n",
        "\n",
        "### Citation:\n",
        "```\n",
        "@article{xia2025pytorchfire,\n",
        " title = {PyTorchFire: A GPU-accelerated wildfire simulator with Differentiable Cellular Automata},\n",
        " author = {Zeyu Xia and Sibo Cheng},\n",
        " journal = {Environmental Modelling & Software},\n",
        " volume = {188},\n",
        " pages = {106401},\n",
        " year = {2025},\n",
        " doi = {10.1016/j.envsoft.2025.106401}\n",
        "}\n",
        "```\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "913246d3662040529a7b9df8714c76b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e7bb4ee4e9da487da6d43ce58ec78406",
              "IPY_MODEL_f5f49136d8ae46e49a0495f2164e7df7",
              "IPY_MODEL_77a2b77a23bf4692904a3c1f50a704d7"
            ],
            "layout": "IPY_MODEL_121ae8b84e4b4ae2a9dc2c12cc34f412"
          }
        },
        "e7bb4ee4e9da487da6d43ce58ec78406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e5436c5238b4d34b3b0dcea0570a4c2",
            "placeholder": "​",
            "style": "IPY_MODEL_78955379e7ab4e82b21019da6ce734ae",
            "value": "7a24816a4952603a93f5c40ebc1bee4b.zip: 100%"
          }
        },
        "f5f49136d8ae46e49a0495f2164e7df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e646ebd2514f4aa3ada7090b9d0cf335",
            "max": 44304,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d1675fe36dd542978e6192aa166e4ed2",
            "value": 44304
          }
        },
        "77a2b77a23bf4692904a3c1f50a704d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72aedf81d9d446baa8df2e0ec9d11426",
            "placeholder": "​",
            "style": "IPY_MODEL_9c143741da134a6b8bee8cd0ad9359a8",
            "value": " 43.3k/43.3k [00:00&lt;00:00, 49.3kB/s]"
          }
        },
        "121ae8b84e4b4ae2a9dc2c12cc34f412": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "2e5436c5238b4d34b3b0dcea0570a4c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78955379e7ab4e82b21019da6ce734ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e646ebd2514f4aa3ada7090b9d0cf335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1675fe36dd542978e6192aa166e4ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "72aedf81d9d446baa8df2e0ec9d11426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c143741da134a6b8bee8cd0ad9359a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}